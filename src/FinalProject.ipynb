{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch\n",
    "import torchaudio.transforms as T\n",
    "import noisereduce as nr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET CLASS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, root_dir, task=\"gender\", transform=None, feature_extractor=None, n_persons=None, seed=42, \n",
    "                 use_preprocessed=False, preprocessed_dir=\"preprocessed\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Path to the directory containing the audio files.\n",
    "            task (str): The task to perform. Options are \"gender\" or \"owner\".\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            feature_extractor (callable, optional): Function to extract features from the waveform.\n",
    "            n_persons (int, optional): Number of unique persons (studentIDs) to include for owner classification.\n",
    "            seed (int, optional): Seed for reproducibility when selecting N persons.\n",
    "            use_preprocessed (bool, optional): Whether to use preprocessed data if available.\n",
    "            preprocessed_dir (str, optional): Directory containing preprocessed features.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.task = task\n",
    "        self.transform = transform\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.n_persons = n_persons\n",
    "        self.seed = seed\n",
    "        self.use_preprocessed = use_preprocessed\n",
    "        self.preprocessed_dir = preprocessed_dir\n",
    "\n",
    "        self.data = []\n",
    "        self.student_ids = set()\n",
    "\n",
    "        # Load and parse filenames\n",
    "        for file in os.listdir(root_dir):\n",
    "            if file.endswith(\".mp3\"):\n",
    "                parts = file[:-4].split(\"_\")  # Remove .mp3 and split by _\n",
    "\n",
    "                # Validate file naming format\n",
    "                if len(parts) == 4 and parts[0].startswith(\"HW\") and \\\n",
    "                   (parts[1] == \"intro\" or parts[1].startswith(\"Q\")) and \\\n",
    "                   parts[3] in [\"male\", \"female\"]:\n",
    "\n",
    "                    try:\n",
    "                        homework_number = int(parts[0][2:])\n",
    "                        question_number = None if parts[1] == \"intro\" else int(parts[1][1:])\n",
    "                        student_id = parts[2]\n",
    "                        gender = parts[3]\n",
    "\n",
    "                        self.data.append({\n",
    "                            \"file_path\": os.path.join(root_dir, file),\n",
    "                            \"homework_number\": homework_number,\n",
    "                            \"question_number\": question_number,\n",
    "                            \"student_id\": student_id,\n",
    "                            \"gender\": gender\n",
    "                        })\n",
    "\n",
    "                        self.student_ids.add(student_id)\n",
    "                    except ValueError:\n",
    "                        # Skip files with invalid formats\n",
    "                        continue\n",
    "\n",
    "        if task == \"owner\" and n_persons is not None:\n",
    "            random.seed(seed)\n",
    "            selected_ids = random.sample(self.student_ids, n_persons)\n",
    "            self.data = [item for item in self.data if item[\"student_id\"] in selected_ids]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        if self.use_preprocessed and self.preprocessed_dir:\n",
    "            preprocessed_path = os.path.join(self.preprocessed_dir, os.path.basename(sample[\"file_path\"]))\n",
    "            if os.path.exists(preprocessed_path):\n",
    "                return torchaudio.load(preprocessed_path)\n",
    "\n",
    "        file_path = sample[\"file_path\"]\n",
    "\n",
    "        # Load audio\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "        # Resample to a consistent rate\n",
    "        target_sample_rate = 16000\n",
    "        if sample_rate != target_sample_rate:\n",
    "            resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "            sample_rate = target_sample_rate\n",
    "\n",
    "        # Apply noise reduction\n",
    "        waveform = nr.reduce_noise(y=waveform.numpy(), sr=sample_rate)\n",
    "        waveform = torch.tensor(waveform)\n",
    "\n",
    "        # Normalize waveform\n",
    "        waveform = (waveform - waveform.mean()) / (waveform.std() + 1e-7)\n",
    "\n",
    "        # Apply transform if specified\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        # Extract features if feature_extractor is specified\n",
    "        if self.feature_extractor:\n",
    "            features = self.feature_extractor(waveform, sample_rate)\n",
    "        else:\n",
    "            features = waveform\n",
    "\n",
    "        if self.task == \"gender\":\n",
    "            label = 0 if sample[\"gender\"] == \"male\" else 1\n",
    "        elif self.task == \"owner\":\n",
    "            label = sample[\"student_id\"]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported task. Use 'gender' or 'owner'.\")\n",
    "\n",
    "        return {\n",
    "            \"features\": features,\n",
    "            \"sample_rate\": sample_rate,\n",
    "            \"label\": label,\n",
    "            \"metadata\": sample\n",
    "        }\n",
    "\n",
    "    def preprocess_and_save(self):\n",
    "        \"\"\"\n",
    "        Preprocess and save features to disk as MP3 files to avoid reloading and reprocessing large datasets.\n",
    "        \"\"\"\n",
    "        os.makedirs(self.preprocessed_dir, exist_ok=True)\n",
    "        for sample in tqdm(self.data, desc=\"Processing Audio Files\"):\n",
    "            file_path = sample[\"file_path\"]\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "            # Resample to a consistent rate\n",
    "            target_sample_rate = 44100\n",
    "            if sample_rate != target_sample_rate:\n",
    "                resampler = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "                waveform = resampler(waveform)\n",
    "                sample_rate = target_sample_rate\n",
    "\n",
    "            # # Apply noise reduction\n",
    "\n",
    "            # # Normalize waveform\n",
    "            waveform = (waveform - waveform.mean()) / (waveform.std() + 1e-7)\n",
    "\n",
    "            waveform = nr.reduce_noise(y=waveform.numpy(), sr=target_sample_rate)\n",
    "            waveform = torch.tensor(waveform)\n",
    "            # Convert to Pydub AudioSegment for MP3 saving\n",
    "\n",
    "            # Save preprocessed audio as MP3\n",
    "            save_path = os.path.join(self.preprocessed_dir, os.path.basename(file_path))\n",
    "            torchaudio.save(save_path, waveform, target_sample_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = AudioDataset(\"../../HW1_M\", preprocessed_dir=\"../../preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Audio Files:  10%|â–ˆ         | 69/676 [01:06<07:54,  1.28it/s]"
     ]
    }
   ],
   "source": [
    "myData.preprocess_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
